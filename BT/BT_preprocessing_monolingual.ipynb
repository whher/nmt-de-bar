{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing of monolingual data for back-translation\n",
    "\n",
    "# Sennrich et al. (2015) argued to back-translate target monolingual data to enlarge parallel training corpus.\n",
    "# Here we subsample 10K monolingual target sentences from both languages,\n",
    "# i.e. monolingual German data will be translated to Bavarian and appended to the bar-de parallel corpus, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de-bar/mono/wikipedia.bar']\n",
      "['bar-de/mono/wikipedia-1.de', 'bar-de/mono/WikiMatrix.bar-de.de', 'bar-de/mono/wikinews.de']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# get all files based on language\n",
    "de_path = \"bar-de/mono\"\n",
    "bar_path = \"de-bar/mono\"\n",
    "de_files = glob.glob(de_path + \"/*.de\")\n",
    "bar_files = glob.glob(bar_path + \"/*.bar\")\n",
    "\n",
    "print(bar_files)\n",
    "print(de_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files into list as lines\n",
    "            \n",
    "de_lines = []\n",
    "\n",
    "for file in de_files:\n",
    "    with open(file) as f:\n",
    "        for line in f.readlines():\n",
    "            de_lines.append(line.rstrip(\" \\n\"))\n",
    "            \n",
    "bar_lines = []\n",
    "\n",
    "for file in bar_files:\n",
    "    with open(file) as f:\n",
    "        for line in f.readlines():\n",
    "            bar_lines.append(line.rstrip(\" \\n\"))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bavarian Monolingual Lines Total:  295083\n",
      "German Monolingual Lines Total:  458428\n"
     ]
    }
   ],
   "source": [
    "# check no. of lines\n",
    "\n",
    "print(\"Bavarian Monolingual Lines Total: \", len(bar_lines))\n",
    "print(\"German Monolingual Lines Total: \", len(de_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Info über die Sonderausstellung zu den Werken von Margit Schötschel in Bernau, abgerufen am 19. Dezember 2018.', 'Therapiestunden mit Gesellschaftsspielcharakter.', 'Behinderte stellen im Amt Panketal aus., Märkische Oderzeitung, 22.', 'April 1998 Kunst ist Kunst, Märkische Oderzeitung, 13.', 'Juni 2008; abgerufen am 15.']\n",
      "['1999/2000 woar die Aunzohl der Bauflächn auf 231 angewachsen und 2009/2010 bestanden 122 Gebäude auf 237 Bauflächn.', 'De Katastralgmoa ist laundwirtschoftli prägt.', '198 Hektar sand zum Johreswexl 1979/1980 laundwirtschoftli gnutzt gwesn und 333 Hektar woarn forstwirtschaftli gefiahrte Woidflächn.', '1999/2000 is auf 161 Hektar Laundwirtschaft betriebn wordn und 361 Hektar sand ois forstwirtschaftli gnutzte Flächn ausgwiesn gwesn.', 'Ende 2018 woarn 153 Hektar ois laundwiatschoftliche Flächn gnutzt und Foastwirtschoft is auf 359 Hektar betriebn woarn.']\n"
     ]
    }
   ],
   "source": [
    "print(de_lines[100:105])\n",
    "print(bar_lines[100:105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  de\n",
      "0                                                   \n",
      "1  Facultas ist ein österreichischer Verlag und B...\n",
      "2  Die aus der Fusion zweier 1976 gegründeten Kop...\n",
      "3    2013 waren mehr als 100 Mitarbeiter angestellt.\n",
      "4  Die Gesellschaft ist spezialisiert auf Fachlit...\n",
      "                                                 bar\n",
      "0                                                   \n",
      "1                                                   \n",
      "2  Sappho (boarische Aussproch: [ˈsapfoː]; attisc...\n",
      "3  Se guit ois de bedeitandste Lyrikarin vom klas...\n",
      "4  Se hod z Mytilene auf da Insl Lesbos glebt, am...\n"
     ]
    }
   ],
   "source": [
    "# transform lists of lines into dataframe\n",
    "\n",
    "de_df = pd.DataFrame(de_lines, columns = [\"de\"])\n",
    "bar_df = pd.DataFrame(bar_lines, columns = [\"bar\"])\n",
    "\n",
    "print(de_df.head())\n",
    "print(bar_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # remove parenthesized texts\n",
    "    text = re.sub(r\"\\(.*?\\)\", \"\", text)\n",
    "    \n",
    "    # remove brackets\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "\n",
    "    # remove quotation marks\n",
    "    text = re.sub(r'(\\<|\\>|\"|“|”|„|»|«)*', \"\", text)\n",
    "\n",
    "    # remove http websites\n",
    "    text = re.sub(r\"(https?:\\/\\/)[a-zA-Z1-9_.@?=#\\/*]*\", \"\", text)\n",
    "\n",
    "    # remove other symbols\n",
    "    text = re.sub(r\"(\\*|\\+|@|#|:|;)*\", \"\", text)\n",
    "    \n",
    "    # remove parenthesis again\n",
    "    text = text.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "\n",
    "    # trim extra whitespace\n",
    "    text = re.sub(r' {2,100}', \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_df[\"de\"] = de_df[\"de\"].apply(preprocess)\n",
    "bar_df[\"bar\"] = bar_df[\"bar\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smart truncate sentences so that sentences are not too long\n",
    "# https://stackoverflow.com/questions/250357/truncate-a-string-without-ending-in-the-middle-of-a-word\n",
    "\n",
    "def smart_truncate(content, length = 90, suffix = '.'):\n",
    "    if len(content) <= length:\n",
    "        return content\n",
    "    else:\n",
    "        return ' '.join(content[:length + 1].split(' ')[0:-1]) + suffix\n",
    "    \n",
    "de_df[\"de\"] = de_df[\"de\"].apply(smart_truncate)\n",
    "bar_df[\"bar\"] = bar_df[\"bar\"].apply(smart_truncate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates and empty lines\n",
    "de_df = de_df.dropna()\n",
    "bar_df = bar_df.dropna()\n",
    "\n",
    "de_df = de_df.drop_duplicates(subset = [\"de\"])\n",
    "bar_df = bar_df.drop_duplicates(subset = [\"bar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bavarian Monolingual Lines Total:  209999\n",
      "German Monolingual Lines Total:  425935\n"
     ]
    }
   ],
   "source": [
    "print(\"Bavarian Monolingual Lines Total: \", len(bar_df))\n",
    "print(\"German Monolingual Lines Total: \", len(de_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   bar\n",
      "229  a met mit ana rassn gwiazmischung is a drochnb...\n",
      "230      da met is woarscheinle ejta ois wia da wein .\n",
      "231  ma braucht an wassrign heng nua lang gmua steh...\n",
      "                                                    de\n",
      "208               jahrhunderts zunehmend an bedeutung.\n",
      "209  bekanntester vertreter war der hamburger theol...\n",
      "210  wichern gab gefährdeten jugendlichen aus hambu...\n"
     ]
    }
   ],
   "source": [
    "print(bar_df[200:203])\n",
    "print(de_df[200:203])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_df_sampled = bar_df.sample(n = 10000, random_state = 1)\n",
    "de_df_sampled = de_df.sample(n = 10000, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize texts\n",
    "def nltk_tokenize(text):\n",
    "    tokenized = word_tokenize(text)\n",
    "    try:\n",
    "        if len(tokenized[-1]) != 1:\n",
    "            tokenized.append(\".\")\n",
    "        return \" \".join(tokenized)\n",
    "    except:\n",
    "        None\n",
    "\n",
    "de_df_sampled[\"de\"] = de_df_sampled[\"de\"].apply(nltk_tokenize)\n",
    "bar_df_sampled[\"bar\"] = bar_df_sampled[\"bar\"].apply(nltk_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156962</th>\n",
       "      <td>ois dag wiad heitzdog gern a topfndag gnumma .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133641</th>\n",
       "      <td>da gscheite woa ollawäu da zwickl .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179747</th>\n",
       "      <td>genau so wia de englenda heit butterfly song ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270179</th>\n",
       "      <td>heit san de sioux in vui vaschiedane reservate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81817</th>\n",
       "      <td>da bauhnhof wean südtirolerplotz is des , wos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36350</th>\n",
       "      <td>f5f1f0f1 feldham is a urtschoft und a katastra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250617</th>\n",
       "      <td>verein für computergenealogie e.v. , abgerufen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53974</th>\n",
       "      <td>de kirch übt aa an wesentlichen einfluss auf d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249373</th>\n",
       "      <td>anno 2000 hamd um de 30,6 million leid a dem g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23347</th>\n",
       "      <td>des is damit noch da karls-universität prag de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      bar\n",
       "156962     ois dag wiad heitzdog gern a topfndag gnumma .\n",
       "133641                da gscheite woa ollawäu da zwickl .\n",
       "179747  genau so wia de englenda heit butterfly song ,...\n",
       "270179  heit san de sioux in vui vaschiedane reservate...\n",
       "81817   da bauhnhof wean südtirolerplotz is des , wos ...\n",
       "...                                                   ...\n",
       "36350   f5f1f0f1 feldham is a urtschoft und a katastra...\n",
       "250617  verein für computergenealogie e.v. , abgerufen...\n",
       "53974   de kirch übt aa an wesentlichen einfluss auf d...\n",
       "249373  anno 2000 hamd um de 30,6 million leid a dem g...\n",
       "23347   des is damit noch da karls-universität prag de...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar_df_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(de_path + \"/BT-de-sampled.txt\", \"w\") as file:\n",
    "    for line in de_df_sampled[\"de\"]:\n",
    "        file.write(line + \"\\n\")\n",
    "    file.write(\"*****\")\n",
    "        \n",
    "with open(bar_path + \"/BT-bar-sampled.txt\", \"w\") as file:\n",
    "    for line in bar_df_sampled[\"bar\"]:\n",
    "        file.write(line + \"\\n\")\n",
    "    file.write(\"*****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {},
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 5
}